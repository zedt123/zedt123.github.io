[
  {
    "objectID": "posts/Diffusion_Code/ddpm_to_sde_tutorial.html",
    "href": "posts/Diffusion_Code/ddpm_to_sde_tutorial.html",
    "title": "SDE/DDPM Connection Tutorial",
    "section": "",
    "text": "As we know there are two formulations of diffusion models (DDPM, SDE Diffusion) . In this tutorial we show their relationship with a toy example. Diffusion models start from samples from a simple distribution (usually \\(\\mathcal{N}(0,1)\\)) and iteratively transform them to generate samples from a target distribution (in our example \\(\\mathcal{N}(5,2^2)\\)). To do so we often need to train a neural network using samples from the target distribution.\nWe start with the Markov Chain formulation of the diffusion models, also known as DDPMs. The forward process (data to noise) is:\n\\[\\boldsymbol{x}_t = \\sqrt{1 - \\beta_t} \\, \\boldsymbol{x}_{t-1} + \\sqrt{\\beta_t} \\, \\boldsymbol{z}_{t-1}, \\quad \\boldsymbol{z}_{t-1} \\sim \\mathcal{N}(0, I), \\quad t=1, \\ldots, N\\]\nwhich can be done in a single step:\n\\[\\boldsymbol{x}_t = \\sqrt{\\bar{\\alpha_t}} \\, \\boldsymbol{x}_{0} + \\sqrt{1-\\bar{\\alpha}_t} \\, \\boldsymbol{z}_{t-1}, \\quad \\boldsymbol{z}_{t-1} \\sim \\mathcal{N}(0, I), \\quad t=1, \\ldots, N\\]\nThe reverse Markov Chain uses a neural network that (often) estimates the noise that needs to be removed:\n\\[\\boldsymbol{x}_t=\\frac{1}{\\sqrt{1-\\beta_t}}\\left(\\boldsymbol{x}_{t+1}-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}(\\boldsymbol{x}_{t+1},t+1)\\right)+ \\sqrt{\\beta_t} \\, \\boldsymbol{z}_{t-1}\\]\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass SimpleNet(nn.Module):\n    def __init__(self, input_dim=2, hidden_dim=128, num_layers=10, time_embedding_dim=128):\n        super(SimpleNet, self).__init__()\n        self.time_embedding = nn.Sequential(\n            nn.Linear(1, time_embedding_dim),\n            nn.ReLU(),\n            nn.Linear(time_embedding_dim, time_embedding_dim),\n            nn.ReLU()\n        )\n        \n        layers = []\n        self.first_layer = nn.Sequential(nn.Linear(input_dim,hidden_dim),\n                                            nn.ReLU())\n        layers.append(nn.ReLU())\n        \n        for _ in range(num_layers - 2):\n            layers.append(nn.Linear(hidden_dim, hidden_dim))\n            layers.append(nn.ReLU())\n        \n        # Final layer mustn't have an activation\n        layers.append(nn.Linear(hidden_dim, input_dim))\n        \n        self.net = nn.Sequential(*layers)\n    \n    def forward(self, x, t):\n        t = t.unsqueeze(1).float()\n        t_emb = self.time_embedding(t)\n        x = self.first_layer(x)\n        x = x + t_emb\n        out = self.net(x)\n        return out\n    \nclass DDPM(nn.Module):\n    def __init__(self, num_timesteps, model):\n        super(DDPM, self).__init__()\n        self.num_timesteps = num_timesteps  \n        self.model = model\n        self.beta = torch.linspace(0.0001, 0.02, num_timesteps)\n        self.alpha = 1 - self.beta\n        self.alpha_bar = torch.cumprod(self.alpha,dim=0)\n\n        self.sqrt_beta = torch.sqrt(self.beta)\n        self.sqrt_alpha_bar = torch.sqrt(self.alpha_bar)\n        self.sqrt_one_alpha_bar = torch.sqrt(1-self.alpha_bar)\n        self.reverse_factor = 1 / torch.sqrt(1-self.beta)\n        self.reverse_factor_2 = torch.sqrt(1-self.alpha_bar)\n    \n    def reverse_diff(self, sample_size):\n        self.model.eval()\n        with torch.inference_mode():\n            samples = torch.zeros((self.num_timesteps+1, sample_size))\n            samples[-1] = torch.randn(sample_size)\n            for t in range(self.num_timesteps-1,-1,-1):\n                t_tensor = torch.ones((1)) * (t+1)\n                noise_hat = self.model(samples[t+1].unsqueeze(1), t_tensor)\n                noise_hat = noise_hat.squeeze(1)\n                exact_sample = self.reverse_factor[t] * (samples[t+1] - self.beta[t] / self.reverse_factor_2[t] * noise_hat)\n                if t != 0:\n                    samples[t] = exact_sample + self.sqrt_beta[t] * torch.randn(sample_size)\n                else:\n                    samples[t] = exact_sample\n            return samples\n    \n    def forward(self, x_0):\n        B = x_0.shape[0]\n        t = torch.randint(1, self.num_timesteps+1, (B,))\n        epsilon = torch.randn((B))\n        x_t = self.sqrt_alpha_bar[t-1] * x_0 + self.sqrt_one_alpha_bar[t-1] * epsilon\n        x_t = x_t.unsqueeze(1)\n        noise_pred = self.model(x_t, t)\n        return noise_pred, epsilon\n    \nclass train_ddpm:\n    def __init__(self, diffusion, mean=5, sd=2):\n        self.diffusion = diffusion\n        data = torch.randn(50000) * sd + mean\n        self.train_loader = DataLoader(data, 256)\n        self.optim = torch.optim.AdamW(self.diffusion.model.parameters(), lr=0.001)\n        self.loss = torch.nn.MSELoss()\n    def train(self, epochs):\n        self.diffusion.model.train()\n        for i in range(epochs):\n            if i%5 == 0:\n                currect_loss = []\n            for x in self.train_loader:\n                self.optim.zero_grad()\n                noise_pred, noise = self.diffusion(x)\n                noise_pred = noise_pred.squeeze(1)\n                loss = self.loss(noise_pred, noise)\n                loss.backward()\n                self.optim.step()\n                if i%5 == 0:\n                    currect_loss.append(loss.detach().numpy())\n            if i%5 == 0:\n                print(f\"Epoch: {i}/{epochs} Loss: {np.mean(currect_loss):.4f}\")\n\n\nmodel = SimpleNet(input_dim=1)\ndiffusion = DDPM(1000, model)\ntrain_class = train_ddpm(diffusion)\ntrain_class.train(50)\n\nsamples = diffusion.reverse_diff(10000).numpy()\nplot_sample = samples[0]\nprint(f\"Estimated mean is {np.mean(plot_sample)}\")\nprint(f\"Estimated std is {np.std(plot_sample)}\")\nplt.hist(plot_sample, density=True)\n\n# Define parameters for the normal distribution\nmean = 5.0\nstd = 2.0\n\n# Create a range of x values\nxmin, xmax = plt.xlim()\nx = torch.linspace(xmin, xmax, 200).numpy()\n\n# Compute the normal PDF: (1/(σ√(2π))) exp(-(x-μ)²/(2σ²))\npdf = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - mean)/std)**2)\n\n# Plot the PDF line\nplt.plot(x, pdf, 'r', linewidth=2)\n\nplt.show()\n\nEpoch: 0/50 Loss: 0.9064\n\n\nThe SDE approach for Diffusion Models starts with a sample \\(\\boldsymbol{x}(0)\\) that propagates through time to evolve to pure noise \\(\\boldsymbol{x}(1)\\) according to the following forward equation: \\[d\\boldsymbol{x}=\\boldsymbol{f}(\\boldsymbol{x},t)+g(t)d\\boldsymbol{w}\\]\nThere are many possible choices for the functions \\(\\boldsymbol{f}(\\boldsymbol{x},t)\\) and \\(g(t)\\) but to have a discretisation of the SDE to be equivalent to the the limit of the Markov Chain (as \\(N \\to \\infty\\)) we need to use the following forward equation:\n\\[d\\boldsymbol{x}=-\\frac{1}{2}\\beta(t)\\boldsymbol{x}(t)+\\sqrt{\\beta(t)}d\\boldsymbol{w},\\]\nwith \\(\\beta(t):= \\bar{\\beta}_{t+\\Delta t}:=N\\beta_{tN+1}\\) at the points of discretisation. \\(\\Delta t\\) is the time between two consectutive points in the discretisation.\nThe general reverse process to transform pure noise \\(\\boldsymbol{x}(1)\\) to a data sample \\(\\boldsymbol{x}(0)\\) is the following:\n\\[d\\boldsymbol{x}=\\left[\\boldsymbol{f}(\\boldsymbol{x},t)-g(t)^2\\nabla_{\\boldsymbol{x}}\\log p_t(\\boldsymbol{x})\\right]dt+g(t)d\\bar{\\boldsymbol{w}}\\]\nwhere \\(\\nabla_{\\boldsymbol{x}}\\log p_t(\\boldsymbol{x})\\) is known as the score function and for any real world datasets needs to be approximated using a Neural Network. For the particular forward SDE we chose here we have:\n\\[d\\boldsymbol{x}=\\left[-\\frac{1}{2}\\beta(t)\\boldsymbol{x}(t)-\\beta(t)\\nabla_{\\boldsymbol{x}}\\log p_t(\\boldsymbol{x})\\right]dt+\\sqrt{\\beta(t)}d\\bar{\\boldsymbol{w}}\\]\nThen, we can propagate \\(\\boldsymbol{x}(0)\\) using the Euler-Maruyama method (or any other SDE solver) to obtain \\(\\boldsymbol{x}(1)\\) according to a discritisation with \\(N\\) discrete steps (same as the Markov Chain). We update the samples every \\(\\Delta t=\\frac{1}{N}\\):\n\\[x_{t}=x_{t-\\Delta t}-\\frac{1}{2}\\bar{\\beta}_{t}x_{t-\\Delta t}\\Delta t+\\sqrt{\\bar{\\beta}_{t}\\Delta t}\\boldsymbol{z}_{t},\\]\nwhere \\(\\boldsymbol{z}_{t}\\) is an isotropic Gaussian random vector. To obtain a sample \\(\\boldsymbol{x}(0)\\) from \\(\\boldsymbol{x}(1)\\) we iteratively update:\n\\[x_{t}=x_{t+\\Delta t}+\\left[\\frac{1}{2}\\bar{\\beta}_{t}x_{t+\\Delta t}+\\bar{\\beta}_{t}\\nabla_{\\boldsymbol{x}_{x+\\Delta t}}\\log p_{t+\\Delta t}(\\boldsymbol{x}_{t+\\Delta t})\\right]\\Delta t+\\sqrt{\\bar{\\beta}_{t}\\Delta t}\\boldsymbol{z}_{t}\\]\nWe follow the previous example where we want to sample from a \\(\\mathcal{N}(5,2^2)\\) distribution. In this case we know the exact score function:\n\\[\\nabla_x\\log p_t(x)=\\nabla_x\\log \\left(\\mathcal{N}(x;5\\sqrt{\\bar{\\alpha}_{tN}},3\\bar{\\alpha}_{tN}+1)\\right)=\\frac{5\\sqrt{\\bar{\\alpha}_{tN}}-x}{3\\bar{\\alpha}_{tN}+1}\\]\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass SDE_DIFF:\n    def __init__(self, num_timesteps):\n        self.num_timesteps = num_timesteps\n        self.dt = 1/num_timesteps\n        self.beta_bar = torch.linspace(0.0001, 0.02, num_timesteps) * num_timesteps # (beta_0,...,beta_{N-1})\n        self.beta_dt = self.beta_bar * self.dt\n        self.sqrt_beta_dt = torch.sqrt(self.beta_dt)\n\n        self.ddpm_beta = torch.linspace(0.0001, 0.02, num_timesteps)\n        self.alpha = torch.cumprod(1 - self.ddpm_beta, dim=0)\n        self.sqrt_alpha = torch.sqrt(self.alpha)\n    def forward_diff(self, x):\n        B = x.shape[0]\n        for t in range(self.num_timesteps):\n            x = x - 0.5 * self.beta_dt[t] * x + self.sqrt_beta_dt[t] * torch.randn(B)\n        return x\n    def reverse_diff(self, num_samples):\n        samples = torch.zeros((self.num_timesteps+1,num_samples))\n        samples[self.num_timesteps] = torch.randn(num_samples)\n        for t in range(self.num_timesteps-1,-1,-1):\n            drift = 0.5 * samples[t+1] + self.score(samples[t+1],t+1)\n            diff = self.sqrt_beta_dt[t] * torch.randn(num_samples)\n            samples[t] = samples[t+1] + drift * self.beta_dt[t] + diff\n        return samples\n    def score(self,x,t):\n        numerator = 5 *self.sqrt_alpha[t-1] - x\n        denomenator = 3 * self.alpha[t-1] + 1\n        return numerator / denomenator\n    \nsde_diff = SDE_DIFF(1000)\nsamples = sde_diff.reverse_diff(10000).numpy()\n\nplot_sample = samples[0]\n\nprint(f\"Estimated mean is {np.mean(plot_sample)}\")\nprint(f\"Estimated std is {np.std(plot_sample)}\")\nplt.hist(plot_sample, density=True)\n\n# Define parameters for the normal distribution\nmean = 5.0\nstd = 2.0\n\n# Create a range of x values\nxmin, xmax = plt.xlim()\nx = torch.linspace(xmin, xmax, 200).numpy()\n\n# Compute the normal PDF: (1/(σ√(2π))) exp(-(x-μ)²/(2σ²))\npdf = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - mean)/std)**2)\n\n# Plot the PDF line\nplt.plot(x, pdf, 'r', linewidth=2)\n\nplt.show()\n\nEstimated mean is 4.95744514465332\nEstimated std is 2.0066986083984375\n\n\n\n\n\n\n\n\n\nNow how do we use the DDPM formulation of diffusion with the exact score? We can derive the following relationship between the score and the error estimation that the neural network estimates:\n\\[\\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1)=-\\sqrt{1 - \\bar{\\alpha}_t}\\nabla_{\\boldsymbol{x}}\\log p_{t+1}(\\boldsymbol{x}_{t+1})\\]\n\nimport torch\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n    \nclass Exact_DDPM():\n    def __init__(self, num_timesteps):\n        super(Exact_DDPM, self).__init__()\n        self.num_timesteps = num_timesteps  \n        self.beta = torch.linspace(0.0001, 0.02, num_timesteps)\n        self.alpha = 1 - self.beta\n        self.alpha_bar = torch.cumprod(self.alpha,dim=0)\n\n        self.sqrt_beta = torch.sqrt(self.beta)\n        self.sqrt_alpha_bar = torch.sqrt(self.alpha_bar)\n        self.sqrt_one_alpha_bar = torch.sqrt(1-self.alpha_bar)\n        self.reverse_factor = 1 / torch.sqrt(1-self.beta)\n        self.reverse_factor_2 = torch.sqrt(1-self.alpha_bar)\n    \n    def reverse_diff(self, sample_size):\n        with torch.inference_mode():\n            samples = torch.zeros((self.num_timesteps+1, sample_size))\n            samples[-1] = torch.randn(sample_size)\n            for t in range(self.num_timesteps-1,-1,-1):\n                # noise_hat =  - self.score(samples[t+1], t+1) * self.reverse_factor_2[t]\n                # exact_sample = self.reverse_factor[t] * (samples[t+1] - self.beta[t] / self.reverse_factor_2[t] * noise_hat)\n                # Note that this is equivalent to just:\n                exact_sample = self.reverse_factor[t] * (samples[t+1] + self.beta[t]  * self.score(samples[t+1], t+1))\n                if t != 0:\n                    samples[t] = exact_sample + self.sqrt_beta[t] * torch.randn(sample_size)\n                else:\n                    samples[t] = exact_sample\n            return samples\n    \n    def score(self,x,t):\n        numerator = 5 *self.sqrt_alpha_bar[t-1] - x\n        denomenator = 3 * self.alpha_bar[t-1] + 1\n        return numerator / denomenator    \n    \n\n\ndiffusion = Exact_DDPM(1000)\n\nsamples = diffusion.reverse_diff(10000).numpy()\nplot_sample = samples[0]\nprint(f\"Estimated mean is {np.mean(plot_sample)}\")\nprint(f\"Estimated std is {np.std(plot_sample)}\")\nplt.hist(plot_sample, density=True)\n\n# Define parameters for the normal distribution\nmean = 5.0\nstd = 2.0\n\n# Create a range of x values\nxmin, xmax = plt.xlim()\nx = torch.linspace(xmin, xmax, 200).numpy()\n\n# Compute the normal PDF: (1/(σ√(2π))) exp(-(x-μ)²/(2σ²))\npdf = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - mean)/std)**2)\n\n# Plot the PDF line\nplt.plot(x, pdf, 'r', linewidth=2)\n\nplt.show()\n\nEstimated mean is 4.997849464416504\nEstimated std is 1.9954274892807007"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andreas Makris",
    "section": "",
    "text": "I am a first year PhD student at Lancaster University, as part of the ProbAI Hub, co-supervised by Prof. Paul Fearnhead and Prof. Chris Nemeth. My research interests include diffusion models, other generative models and causality.\nI hold a Master’s degree in Computing from Imperial College London, where I completed a thesis on training Deep Sequential Latent Variable Models using Sampling Methods under the supervision of Prof. Yingzhen Li. Prior to that, I earned my Bachelor’s degree in Mathematics and Computer Science from Durham University."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Blog",
    "section": "",
    "text": "VE SDE Tutorial\n\n\n\n\n\n\ndiffusion\n\n\ntutorial\n\n\n\nA tutorial to understand the VE Diffusion model using a toy example.\n\n\n\n\n\nDec 17, 2024\n\n\nAndreas Makris\n\n\n\n\n\n\n\n\n\n\n\n\nSDE/DDPM Connection Tutorial\n\n\n\n\n\n\ndiffusion\n\n\ntutorial\n\n\n\nA tutorial to illustrate the connection between DDPM and SDE Diffusion with a toy example.\n\n\n\n\n\nDec 16, 2024\n\n\nAndreas Makris\n\n\n\n\n\n\n\n\n\n\n\n\nDDPM connection to SDEs\n\n\n\n\n\n\ndiffusion\n\n\n\nAn introduction to the two formulations of Diffusion models and their relationship.\n\n\n\n\n\nDec 15, 2024\n\n\nAndreas Makris\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Diffusion/index.html#diffusion-models-with-discrete-markov-chains-ddpms",
    "href": "posts/Diffusion/index.html#diffusion-models-with-discrete-markov-chains-ddpms",
    "title": "DDPM connection to SDEs",
    "section": "Diffusion Models with Discrete Markov Chains (DDPMs)",
    "text": "Diffusion Models with Discrete Markov Chains (DDPMs)\nDiffusion models were popularized by Denoising Diffusion Probabilistic Models (DDPMs) (Ho, Jain, and Abbeel 2020). The core idea is to start with a data distribution \\(p(\\boldsymbol{x}_0)\\) and define a forward diffusion process that gradually adds noise to the data over a finite sequence of time steps \\((\\boldsymbol{x}_0, \\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_T)\\). At each step, Gaussian noise is added according to a predefined schedule \\(\\{\\beta_t\\}_{t=1}^N\\). This process transforms an original data sample \\(\\boldsymbol{x}_0\\) into a nearly pure noise sample \\(\\boldsymbol{x}_T\\). Formally, the forward process is given by:\n\\[\n\\boldsymbol{x}_t = \\sqrt{1 - \\beta_t} \\, \\boldsymbol{x}_{t-1} + \\sqrt{\\beta_t} \\, \\boldsymbol{z}_{t-1}, \\quad \\boldsymbol{z}_{t-1} \\sim \\mathcal{N}(0, I), \\quad t=1, \\ldots, N\n\\]\nA neural network \\(\\hat{\\epsilon}(\\boldsymbol{x}_{i}, i)\\) is then trained to approximate the noise added to reverse the process. That is, starting from noise \\(\\boldsymbol{x}_T \\sim \\mathcal{N}(0, I)\\), we iteratively denoise it until we recover a sample \\(\\boldsymbol{x}_0 \\sim p(\\boldsymbol{x}_0)\\). This reverse procedure is also a Markov chain, but its transition kernels are learned. Once trained, sampling from the model is done by reversing the diffusion process step-by-step:\n\\[\n\\boldsymbol{x}_t = \\frac{1}{\\sqrt{1 - \\beta_t}} \\left( \\boldsymbol{x}_{t+1} - \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1) \\right) + \\sqrt{\\beta_t} \\, \\boldsymbol{z}_{t-1}\n\\]\nwhere we have defined \\(\\bar{\\alpha}_t := \\prod_{s=1}^t \\alpha_s\\). A common choice of hyperparameters in this setting is:\n\\[\n\\begin{align*}\n    N &= 1000, \\\\\n    \\beta_1 &= 10^{-4}, \\\\\n    \\beta_T &= 0.02, \\\\\n    \\beta_t &= \\beta_{t-1} + \\frac{\\beta_N - \\beta_1}{N}, \\quad \\text{for } t=2, \\ldots, N-1  \n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/Diffusion/index.html#diffusion-using-stochastic-differential-equations-sdes",
    "href": "posts/Diffusion/index.html#diffusion-using-stochastic-differential-equations-sdes",
    "title": "DDPM connection to SDEs",
    "section": "Diffusion Using Stochastic Differential Equations (SDEs)",
    "text": "Diffusion Using Stochastic Differential Equations (SDEs)\nAn alternative perspective on diffusion models comes from continuous-time formulations, where the noising process is described as a solution to a Stochastic Differential Equation (SDE) (Song et al. 2021). Instead of a finite number of steps, we imagine a continuous time variable \\(t \\in [0,1]\\) that governs the diffusion of clean data into noise:\n\\[\nd\\boldsymbol{x} = \\boldsymbol{f}(\\boldsymbol{x}, t) \\, dt + g(t) \\, d\\boldsymbol{w},\n\\]\nwhere \\(\\boldsymbol{w}\\) is the standard Wiener process (a.k.a., Brownian motion). If we know the gradient of the distribution of the data with respect to the data (at each \\(t\\)), i.e., \\(\\nabla_{\\boldsymbol{x}} \\log p_t(\\boldsymbol{x})\\), we can reverse this process:\n\\[\nd\\boldsymbol{x} = \\left[ \\boldsymbol{f}(\\boldsymbol{x}, t) - g(t)^2 \\nabla_{\\boldsymbol{x}} \\log p_t(\\boldsymbol{x}) \\right] dt + g(t) \\, d\\bar{\\boldsymbol{w}},\n\\]\nwhere \\(\\bar{\\boldsymbol{w}}\\) is a standard Wiener process when time flows backwards. Note that \\(dt\\) in this equation is negative, as we are propagating from \\(t = 1\\) to \\(t = 0\\). If we do not know \\(\\nabla_{\\boldsymbol{x}} \\log p_t(\\boldsymbol{x})\\), which is also known as the score function, we can approximate it using a Neural Network.\nThere are many possible choices for the functions \\(\\boldsymbol{f}(\\boldsymbol{x}, t)\\) and \\(g(t)\\), but we choose \\(\\boldsymbol{f}(\\boldsymbol{x}, t) = -\\frac{1}{2} \\beta(t) \\boldsymbol{x}(t)\\) and \\(g(t) = \\sqrt{\\beta(t)}\\). We can show that a discretization of the SDE (this particular SDE is known as the VP-SDE) is equivalent to the Markov Chain formulation of the Diffusion Models. In this case, we have the following forward SDE:\n\\[\nd\\boldsymbol{x} = -\\frac{1}{2} \\beta(t) \\boldsymbol{x}(t) \\, dt + \\sqrt{\\beta(t)} \\, d\\boldsymbol{w},\n\\]\nwhich can be reversed by:\n\\[\nd\\boldsymbol{x} = \\left[ -\\frac{1}{2} \\beta(t) \\boldsymbol{x}(t) - \\beta(t) \\nabla_{\\boldsymbol{x}} \\log p_t(\\boldsymbol{x}) \\right] dt + \\sqrt{\\beta(t)} \\, d\\bar{\\boldsymbol{w}}.\n\\]\nFor the two formulations to be “equivalent,” we need to set \\(\\beta(t) := \\bar{\\beta}_{t+\\Delta t} := N \\beta_{tN+1}\\) at the points of discretization. If we use the same hyperparameters as above and discretize the SDE at the same points as the Markov Chain, then we get the following discretization of \\(\\bar{\\beta}_t\\):\n\\[\n\\begin{align*}\n    \\bar{\\beta}_1 &= 0.1, \\\\\n    \\bar{\\beta}_T &= 20, \\\\\n    \\bar{\\beta}_t &= \\bar{\\beta}_{t-1} + \\frac{\\bar{\\beta}_N - \\bar{\\beta}_1}{N}, \\quad \\text{for } t=2, \\ldots, N-1  \n\\end{align*}\n\\]"
  },
  {
    "objectID": "posts/Diffusion/index.html#understanding-sdes",
    "href": "posts/Diffusion/index.html#understanding-sdes",
    "title": "DDPM connection to SDEs",
    "section": "Understanding SDEs",
    "text": "Understanding SDEs\nTo build an intuitive understanding of stochastic differential equations, it helps to get our hands dirty with a straightforward numerical experiment. The idea is to think of an SDE as describing a continuous-time process that evolves with both a deterministic trend (the “drift”) and a random “noise” component that keeps shaking things up as time goes by. This might sound abstract, but we can make it more concrete by actually simulating a path of a simple SDE using the simplest and most intuitive method: the Euler–Maruyama method. To simulate the forward diffusion using the VP-SDE we have formulated above, we do the following:\n\nSet the timestep \\(\\Delta t = 1/N = 0.001\\).\nTake a sample \\(\\boldsymbol{x}_0\\) from our dataset.\nFor \\(t = \\Delta t, 2\\Delta t, \\ldots, 1\\) do\n\nSet \\(\\boldsymbol{x}_{t} = \\boldsymbol{x}_{t-\\Delta t} - \\frac{1}{2} \\bar{\\beta}_t \\boldsymbol{x}_{t-\\Delta t} \\Delta t + \\sqrt{\\bar{\\beta}_t \\Delta t} \\boldsymbol{z}_{t-\\Delta t}\\) where \\(\\boldsymbol{z}_{t-\\Delta t} \\sim \\mathcal{N}(0, I)\\).\n\n\nTo reverse this process (i.e., generate samples that could exist in our dataset):\n\nSample \\(\\boldsymbol{x}_1 \\sim \\mathcal{N}(0, I)\\) from our dataset.\nFor \\(t = 1, (1 - \\Delta t), (1 - 2\\Delta t), \\ldots, \\Delta t\\) do\n\nSet \\(\\boldsymbol{x}_{t} = \\boldsymbol{x}_{t+\\Delta t} + \\left[ \\frac{1}{2} \\bar{\\beta}_{t} \\boldsymbol{x}_{t+\\Delta t} + \\bar{\\beta}_{t} \\nabla_{\\boldsymbol{x}} \\log p_{t+\\Delta t}(\\boldsymbol{x}_{t+\\Delta t}) \\right] \\Delta t + \\sqrt{\\bar{\\beta}_{t} \\Delta t} \\, \\boldsymbol{z}_{t+\\Delta t},\\) where \\(\\boldsymbol{z}_{t+\\Delta t} \\sim \\mathcal{N}(0, I)\\)."
  },
  {
    "objectID": "posts/Diffusion/index.html#showing-the-equivalence",
    "href": "posts/Diffusion/index.html#showing-the-equivalence",
    "title": "DDPM connection to SDEs",
    "section": "Showing the equivalence",
    "text": "Showing the equivalence\nTo show that a discretisation of the SDE is equivalent to the Markov Chain (which is also shown in the appendix of (Song et al. 2021)), we first show that the forward processes are equivalent and then that the reverse processes are equivalent as \\(\\Delta t \\to 0\\) (which is equivalent to \\(N \\to \\infty\\)).\n\nEquivalence of Forward Processes\nWe need to show that:\n\\[\n\\boldsymbol{x}_t = \\sqrt{1 - \\beta_t} \\, \\boldsymbol{x}_{t-1} + \\sqrt{\\beta_t} \\, \\boldsymbol{z}_{t-1} \\iff \\boldsymbol{x}_{t} = \\boldsymbol{x}_{t-1} - \\frac{1}{2} \\bar{\\beta}_t \\boldsymbol{x}_{t-1} \\Delta t + \\sqrt{\\bar{\\beta}_t \\Delta t} \\, \\boldsymbol{z}_{t-1},\n\\tag{1} \\label{eq:equiv_1}\n\\]\nas \\(\\Delta t \\to 0\\), where we use \\(\\boldsymbol{x}_{t-1}\\) rather than \\(\\boldsymbol{x}_{t-\\Delta t}\\) for notational convenience. To show that the equivalence holds, we use the Taylor approximation of \\(f(x) = \\sqrt{1 - x}\\) around \\(x = 0\\):\n\\[\n\\sqrt{1 - x} = 1 - \\frac{x}{2} - \\frac{x^2}{8} - \\ldots\n\\]\nIf we set \\(x = \\bar{\\beta}_t \\Delta t\\), we have:\n\\[\n\\sqrt{1 - \\bar{\\beta}_t \\Delta t} = 1 - \\frac{\\bar{\\beta}_t \\Delta t}{2} - \\frac{\\bar{\\beta}_t \\Delta t^2}{8} - \\ldots\n\\]\nand as \\(\\Delta t\\) approaches 0, the approximation \\(\\sqrt{1 - \\bar{\\beta}_t \\Delta t} \\approx 1 - \\frac{\\bar{\\beta}_t \\Delta t}{2}\\) improves. Then, starting from the left-hand side of Equivalence (\\(\\ref{eq:equiv_1}\\)):\n\\[\n\\begin{align*}\n    \\boldsymbol{x}_t &= \\sqrt{1 - \\beta_t} \\, \\boldsymbol{x}_{t-1} + \\sqrt{\\beta_t} \\, \\boldsymbol{z}_{t-1} \\\\\n    \\iff \\boldsymbol{x}_t &= \\sqrt{1 - \\bar{\\beta}_t \\Delta t} \\, \\boldsymbol{x}_{t-1} + \\sqrt{\\bar{\\beta}_t \\Delta t} \\, \\boldsymbol{z}_{t-1} \\quad \\text{by the definition of } \\bar{\\beta}_t \\\\\n    \\iff \\boldsymbol{x}_t &= \\left(1 - \\frac{\\bar{\\beta}_t \\Delta t}{2}\\right) \\boldsymbol{x}_{t-1} + \\sqrt{\\bar{\\beta}_t \\Delta t} \\, \\boldsymbol{z}_{t-1} \\quad \\text{as } \\Delta t \\to 0 \\\\\n    \\iff \\boldsymbol{x}_{t} &= \\boldsymbol{x}_{t-1} - \\frac{1}{2} \\bar{\\beta}_t \\boldsymbol{x}_{t-1} \\Delta t + \\sqrt{\\bar{\\beta}_t \\Delta t} \\, \\boldsymbol{z}_{t-1}    \n\\end{align*}\n\\]\n\n\nEquivalence of Reverse Processes\nWe need to show that:\n\\[\n    \\boldsymbol{x}_t=\\frac{1}{\\sqrt{1-\\beta_t}}\\left(\\boldsymbol{x}_{t+1}-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}(\\boldsymbol{x}_{t+1},t+1)\\right) \\iff \\boldsymbol{x}_{t} = \\boldsymbol{x}_{t+1} + \\left[\\frac{1}{2}\\bar{\\beta}_{t} \\boldsymbol{x}_{t+1} + \\bar{\\beta}_{t}\\nabla_{\\boldsymbol{x}}\\log p_{t+1}(\\boldsymbol{x}_{t+1})\\right]\\Delta t,\n\\tag{2} \\label{eq:equiv_2}\n\\]\nas \\(\\Delta t \\to 0\\) where we use \\(\\boldsymbol{x}_{t+1}\\) rather than \\(\\boldsymbol{x}_{t+\\Delta t}\\) for notational convenience and have omitted the noise terms for brevity (as we have already shown their equivalence in the previous section). To show that the equivalence holds we use the Taylor approximation of \\(g(x)=\\frac{1}{\\sqrt{1-x}}\\) around \\(x=0\\):\n\\[\\frac{1}{\\sqrt{1-x}}=1+\\frac{x}{2}+\\frac{3x^2}{8}+...\\]\nIf we set \\(x=\\bar{\\beta_t}\\Delta t\\) we have:\n\\[\\frac{1}{\\sqrt{1-\\bar{\\beta_t}\\Delta t}}=1+\\frac{\\bar{\\beta_t}\\Delta t}{2}+\\frac{3\\bar{\\beta_t}\\Delta t^2}{8}+...\\]\nand as \\(\\Delta t\\) approaches 0 the approximation \\(\\frac{1}{\\sqrt{1-\\bar{\\beta_t\\Delta t}}}\\approx 1+\\frac{\\bar{\\beta_t}\\Delta t}{2}\\) improves. Then, starting from the left hand side of equivalence (\\(\\ref{eq:equiv_2}\\)):\n\\[\n\\begin{align*}\n\\boldsymbol{x}_t&=\\frac{1}{\\sqrt{1-\\beta_t}}\\left(\\boldsymbol{x}_{t+1}-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}(\\boldsymbol{x}_{t+1},t+1)\\right) \\\\\n\\iff \\boldsymbol{x}_t &=\\frac{1}{\\sqrt{1-\\bar{\\beta}_t\\Delta t}}\\left(\\boldsymbol{x}_{t+1}-\\frac{\\bar{\\beta}_t\\Delta t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}(\\boldsymbol{x}_{t+1},t+1)\\right), \\text{ by the definition of } \\bar{\\beta}_t \\\\\n\\iff \\boldsymbol{x}_t &= \\left(1+\\frac{\\bar{\\beta_t}\\Delta t}{2}\\right)\\left(\\boldsymbol{x}_{t+1}-\\frac{\\bar{\\beta}_t\\Delta t}{\\sqrt{1-\\bar{\\alpha}_t}}\\hat{\\epsilon}(\\boldsymbol{x}_{t+1},t+1)\\right), \\text{ as } \\Delta t \\to 0 \\\\\n\\iff \\boldsymbol{x}_t &= \\boldsymbol{x}_{t+1} + \\frac{\\bar{\\beta}_t \\Delta t}{2} \\boldsymbol{x}_{t+1} - \\frac{\\bar{\\beta}_t \\Delta t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1) - \\frac{(\\bar{\\beta}_t \\Delta t)^2}{2 \\sqrt{1 - \\bar{\\alpha}_t}} \\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1) \\\\\n\\iff \\boldsymbol{x}_t &= \\boldsymbol{x}_{t+1} + \\frac{\\bar{\\beta}_t \\Delta t}{2} \\boldsymbol{x}_{t+1} - \\frac{\\bar{\\beta}_t \\Delta t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1)\\\\\n\\iff \\boldsymbol{x}_t &= \\boldsymbol{x}_{t+1} + \\left(\\frac{1}{2}\\bar{\\beta}_t\\boldsymbol{x}_{t+1}-\\bar{\\beta}_t\\frac{\\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1)}{\\sqrt{1 - \\bar{\\alpha}_t}} \\right)\\Delta t\n\\end{align*}\n\\]\nTherefore, when the Neural Network that estimates the noise is:\n\\[\\hat{\\epsilon}(\\boldsymbol{x}_{t+1}, t+1)=-\\sqrt{1 - \\bar{\\alpha}_t}\\nabla_{\\boldsymbol{x}}\\log p_{t+1}(\\boldsymbol{x}_{t+1}),\\]\nthe discretisation of the reverse diffusion of the SDE is equivalent to the reverse Markov Chain. In practise, we train neural networks for each of the two formulations and can divide the neural network of the DDPM model by \\(-\\sqrt{1 - \\bar{\\alpha}_t}\\) to obtain an approximation of the score function."
  },
  {
    "objectID": "posts/VP_SDE/ve_sde_tutorial.html",
    "href": "posts/VP_SDE/ve_sde_tutorial.html",
    "title": "VE SDE Tutorial",
    "section": "",
    "text": "In the previous post we have seen the VP Diffusion model. An other popular type of Diffusion models are the Variance Exploding (VE) SDEs:\n\\[d\\boldsymbol{x}=\\sqrt{\\left[\\frac{d}{dt}\\sigma^2(t)\\right]}d\\boldsymbol{w}\\]\nwith the following reverse process:\n\\[d\\boldsymbol{x}=\\left[-\\frac{d}{dt}\\left(\\sigma^2(t)\\right)\\nabla_{\\boldsymbol{x}}\\log p_t(\\boldsymbol{x})\\right]dt+\\sqrt{\\left[\\frac{d}{dt}\\sigma^2(t)\\right]}d\\bar{\\boldsymbol{w}}\\]\nA common choice of the variance function is \\(\\sigma(t)=\\sigma_{\\text{max}}\\left(\\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}}\\right)^t\\), with \\(\\sigma_{\\text{min}}=0.01\\) and \\(\\sigma_{\\text{max}}=50\\). Then, we have that:\n\\[\\frac{d\\sigma(t)^2}{dt}=2\\sigma(t)^2\\left(\\log(\\sigma_{\\text{max}})-\\log(\\sigma_{\\text{min}})\\right)\\]\nLet’s first understand how \\(\\sigma(t)\\) and \\(\\frac{d\\sigma(t)}{dt}\\) change with time.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnum_timesteps = 1000\ndt = 1/num_timesteps\nsigma_min = 0.01\nsigma_max = 50\n\nsigmas = sigma_min * (sigma_max / sigma_min) ** np.linspace(0, 1, 1000)\nd2sigma_dt = 2 * sigmas ** 2 * (np.log(sigma_max) - np.log(sigma_min))\n\n# Create a figure and two subplots side by side\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n\n# First subplot\nax1 = axes[0]\n# Example plot (replace with your data)\nax1.plot(np.linspace(0, 1, 1000), sigmas)\n# Set title and x-label for the first subplot\nax1.set_title(r'Plot of $\\sigma(t)$ with respect to time', fontsize=17)\nax1.set_xlabel(r'$t$', fontsize=17)\nax1.set_ylabel(r'$\\sigma(t)$', fontsize=17)\n\n# Second subplot\nax2 = axes[1]\n# Example plot (replace with your data)\nax2.plot(np.linspace(0, 1, 1000), np.sqrt(d2sigma_dt))\n# Set title and x-label for the second subplot\nax2.set_title(r'Plot of $\\frac{d\\sigma(t)}{dt}$ with respect to time', fontsize=17)\nax2.set_xlabel(r'$t$', fontsize=17)\nax2.set_ylabel(r'$\\frac{d\\sigma(t)}{dt}$', fontsize=17)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Display the plots\nplt.show()\n\n\n\n\n\n\n\n\nNow let’s consider \\(p_0(x)=\\mathcal{N}(5,4)\\) and propagate data samples \\(x(0)\\) to \\(x(1)\\). The distribution of \\(x(1), p_1(x)\\) is some noise distribution we will use to generate data samples, by propagating in reverse time.\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass VE_SDE_DIFF:\n    def __init__(self, num_timesteps):\n        self.num_timesteps = num_timesteps\n        self.dt = 1/num_timesteps\n        self.sigma_min = torch.tensor(0.01)\n        self.sigma_max = torch.tensor(50)\n\n        self.sigmas = self.sigma_min * (self.sigma_max / self.sigma_min) ** torch.linspace(0, 1, num_timesteps)\n        self.d2sigma_dt = 2 * self.sigmas ** 2 * (torch.log(self.sigma_max) - torch.log(self.sigma_min))\n        self.forward_term = torch.sqrt(self.d2sigma_dt * self.dt)\n    def forward_diff(self, x0):\n        B = x0.shape[0]\n        x = torch.zeros((self.num_timesteps+1,B))\n        x[0] = x0\n        for t in range(self.num_timesteps):\n            x[t+1] = x[t] + self.forward_term[t] * torch.randn(B)\n        return x\n    \nve_sde = VE_SDE_DIFF(1000)\nx0 = torch.randn(100000) * 2 + 5\nx = ve_sde.forward_diff(x0).numpy()\n\nplot_sample = x[1000]\n\nprint(f\"Estimated mean is {np.mean(plot_sample)}\")\nprint(f\"Estimated std is {np.std(plot_sample)}\")\nplt.hist(plot_sample, density=True)\n\n# Define parameters for the normal distribution\nmean = 0.0\nstd = 50.0\n\n# Create a range of x values\nxmin, xmax = plt.xlim()\nx = torch.linspace(xmin, xmax, 200).numpy()\n\n# Compute the normal PDF: (1/(σ√(2π))) exp(-(x-μ)²/(2σ²))\npdf = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - mean)/std)**2)\n\n# Plot the PDF line\nplt.plot(x, pdf, 'r', linewidth=2)\n\nplt.show()\n\nEstimated mean is 5.073878288269043\nEstimated std is 50.15424346923828\n\n\n\n\n\n\n\n\n\nNote that for large variance small differences in the mean are negligible. Thus, \\(\\mathcal{N}(5,50^2)\\approx\\mathcal{N}(0,50^2)\\). Consider the case of images, that pixels are normalised between -1 and 1, then the approximation is very good.\n\nx = np.linspace(-200, 200, 200)\n# Compute the normal PDF: (1/(σ√(2π))) exp(-(x-μ)²/(2σ²))\npdf_1 = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - 0.0)/std)**2)\npdf_2 = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - 5.0)/std)**2)\n\n# Plot the PDF line\nplt.plot(x, pdf_1, 'r', linewidth=2, label=r'$\\mathcal{N}(0,50^2)$')\nplt.plot(x, pdf_2, 'g', linewidth=2, label=r'$\\mathcal{N}(5,50^2)$')\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nNow we will use the exact score to perform the reverse diffusion. We assume that \\(p_1(x)=\\mathcal{N}(5,50)\\) (since we now the mean of \\(p_0(x)\\) we can use it instead of 0). Then,\n\\[p_t(x)=\\mathcal{N}(5, 4 + \\sigma_{t}^2 - \\sigma_{\\text{min}}^2)\\]\nand\n\\[\\nabla_x\\log p_t(x)=\\frac{5-x}{4 + \\sigma_{t}^2 - \\sigma_{\\text{min}}^2}\\]\nWe use the exact score to reverse the diffusion process.\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass VE_SDE_DIFF:\n    def __init__(self, num_timesteps):\n        self.num_timesteps = num_timesteps\n        self.dt = 1/num_timesteps\n        self.sigma_min = torch.tensor(0.01)\n        self.sigma_min2 = self.sigma_min ** 2\n        self.sigma_max = torch.tensor(50)\n\n        self.sigmas = self.sigma_min * (self.sigma_max / self.sigma_min) ** torch.linspace(0, 1, num_timesteps)\n        self.sigmas2 = self.sigmas ** 2\n        self.d2sigma_dt = 2 * self.sigmas ** 2 * (torch.log(self.sigma_max) - torch.log(self.sigma_min))\n        self.forward_term = torch.sqrt(self.d2sigma_dt * self.dt)\n    def forward_diff(self, x0):\n        B = x0.shape[0]\n        x = torch.zeros((self.num_timesteps+1,B))\n        x[0] = x0\n        for t in range(self.num_timesteps):\n            x[t+1] = x[t] + self.forward_term[t] * torch.randn(B)\n        return x\n    def reverse_diff(self, num_samples):\n        samples = torch.zeros((self.num_timesteps+1,num_samples))\n        samples[self.num_timesteps] = torch.randn(num_samples) * 50 + 5\n        for t in range(self.num_timesteps-1,-1,-1):\n            drift = self.d2sigma_dt[t] * self.score(samples[t+1],t+1) * self.dt\n            diff = self.forward_term[t] * torch.randn(num_samples)\n            samples[t] = samples[t+1] + drift + diff\n        return samples\n    def score(self,x,t):\n        numerator = 5 - x\n        denomenator = 4 + self.sigmas2[t-1] - self.sigma_min2\n        return numerator / denomenator\n    \nve_sde = VE_SDE_DIFF(1000)\nsamples = ve_sde.reverse_diff(10000).numpy()\n\nplot_sample = samples[0]\n\nprint(f\"Estimated mean is {np.mean(plot_sample)}\")\nprint(f\"Estimated std is {np.std(plot_sample)}\")\nplt.hist(plot_sample, density=True)\n\n# Define parameters for the normal distribution\nmean = 5.0\nstd = 2.0\n\n# Create a range of x values\nxmin, xmax = plt.xlim()\nx = torch.linspace(xmin, xmax, 200).numpy()\n\n# Compute the normal PDF: (1/(σ√(2π))) exp(-(x-μ)²/(2σ²))\npdf = (1/(std * np.sqrt(2*np.pi))) * np.exp(-0.5*((x - mean)/std)**2)\n\n# Plot the PDF line\nplt.plot(x, pdf, 'r', linewidth=2)\n\nplt.show()\n\nEstimated mean is 5.011462688446045\nEstimated std is 1.9858821630477905\n\n\n\n\n\n\n\n\n\nIf you want a sanity check, try modifiying the code above, so that the we sample from \\(\\mathcal{N}(0,50^2)\\) at \\(t=1\\). Note that the score function should not be modified!\nYou can also check what happens if you ignore \\(\\sigma_{\\text{min}}^2\\) in the denominator of the score function. Spoiler alert: it is that small that makes no difference."
  }
]